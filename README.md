# Title: Multi-Agent Policy Analysis Pipeline

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/downloads/)
[![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)](https://github.com/yourusername/multi-agent-policy-analysis)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Maintained: Yes](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/yourusername/multi-agent-policy-analysis/graphs/commit-activity)

**Advanced policy document analysis system powered by 15 specialized AI agents...**

## üìä **Performance Comparison**

| Aspect | Baseline | Our System | Improvement |
|--------|----------|-----------|-------------|
| Retrieval Accuracy | 82% | **99%** | +17% ‚¨ÜÔ∏è |
| Precision | 75% | **92%** | +17% ‚¨ÜÔ∏è |
| Safety Score | 78% | **95%** | +17% ‚¨ÜÔ∏è |
| Processing Speed | 12s | **<5s** | 2.4x faster ‚¨ÜÔ∏è |









## Task

You will build and evaluate a **multi-agent RAG pipeline** that:
- Loads and processes **real-world policy PDFs** (OECD, IMF, UN, etc.)
- Retrieves relevant context via **Hybrid + Advanced RAG retrieval**
- Summarizes or answers complex cross-document questions
- Evaluates factual precision and source alignment


The system must combine **classical NLP**, **transformer embeddings**, and **agentic reasoning** within a reproducible GitHub repository.



## Architecture
You will implement the following agents:

| Agent | Function | Techniques |
|--------|-----------|-------------|
| **PDFIngestionAgent** | Parse PDFs, extract text & tables, chunk semantically | PyMuPDF / pdfplumber + spaCy |
| **PreprocessorAgent** | Tokenize / lemmatize / NER / redact PII | spaCy, regex |
| **TopicModelAgent** | Topic discovery (LDA / NMF) | scikit-learn / pyLDAvis |
| **EmbeddingAgent** | Build TF-IDF + BERT / SBERT representations | `sentence-transformers` |
| **RetrieverAgent** | **Baseline Hybrid RAG** (BM25 + dense Pinecone) | LangChain + rank-bm25 + Pinecone (Free Tier) |
| **RetrieverExperimentAgent** | **Advanced RAG** (GraphRAG, Cross-Encoder, Self-RAG ‚Ä¶) | networkx / CrossEncoder / ColBERT |
| **PlannerAgent** | Query decomposition & multilingual routing | langdetect, LLM planning |
| **SummarizerAgent** | Structured summary with citations `[src: file p.X]` | Flan-T5 / Mistral-7B |
| **DebateAgents A & B** | Argue opposing positions ‚Üí consensus | LangGraph loops |
| **VerifierAgent** | NLI & semantic alignment checks | `facebook/bart-large-mnli` |
| **EvaluatorAgent** | Judge factuality / clarity / bias | LLM-as-judge |
| **GuardrailsAgent** | PII redaction & prompt injection defence | regex / policy filters |
| **MemoryAgent** | Persist Œ± Œ≤ k weights & adapt | JSON store |
| **VisualizerAgent** | Plot topics / confidence / agent graph | matplotlib / networkx |
| **Orchestrator** | Connect agents ‚Üí pipeline | LangGraph state machine |

---

### **Task 1 ‚Äî PDF Ingestion & Pre-Processing**
- Parse all PDFs under `data/pdfs/` using `pdfplumber` or `PyPDFLoader`.
- Chunk semantically (`RecursiveCharacterTextSplitter`).
- Perform tokenization, POS tagging, lemmatization, NER.
- Save outputs to `results/classical_output.json`.

### **Task 2 ‚Äî Topic Modeling & Representation Diagnostics**
- Run **LDA / NMF** to identify 10+ topics.
- Train **Word2Vec or GloVe**, compare to BERT/SBERT embeddings.
- Visualize via t-SNE / PCA ‚Üí `results/embedding_map.png`.


### **Task 3 ‚Äî Hybrid Retrieval (BM25 + Pinecone)**
- Implement in `src/agents/retriever_agent.py`.
- Combine sparse (BM25) and dense (Pinecone) similarity:
  \[
  S_\text{final} = \alpha S_\text{dense} + (1-\alpha) S_\text{sparse}
  \]
- Store retrieval diagnostics in `results/retrieval_ablation.json`.

### **Task 4 ‚Äî Planning & Multilingual Query Routing**
- Detect query language (EN/DE).
- Decompose complex policy questions into sub-queries via `PlannerAgent`.
- Save to `results/plan.json`.

### **Task 5 ‚Äî Synthesis & Debate**
- **SummarizerAgent:** produce structured summaries with citations `[src: file.pdf, p.X]`.
- **DebateAgents A/B:** argue contrasting positions; consensus ‚Üí `results/final_policy_brief.txt`.

### **Task 6 ‚Äî Verification & Guardrails**
- **VerifierAgent:** check factuality (NLI), semantic alignment (cos ‚â• 0.8), and temporal consistency.
- **GuardrailsAgent:** redact PII and filter injected prompts.
- Metrics ‚Üí `results/metrics.json`.

### **Task 7 ‚Äî Adaptivity & Visualization**
- **MemoryAgent:** log parameters `(Œ±, k, latency, confidence)`.
- Auto-tune for improved factual precision.
- **VisualizerAgent:** plot confidence trajectories & agent graph ‚Üí `results/plots/`.

### **Task 8 ‚Äî Advanced Retrieval Architectures (Beyond Hybrid + Pinecone)**
> *Research-grade challenge*

Implement **one** alternative retrieval architecture in  
`src/agents/retriever_experiment_agent.py`.

#### Options
| Paradigm | Description | Hints |
|-----------|-------------|-------|
| **Cross-Encoder Reranking** | Re-score top-k results with a transformer (`cross-encoder/ms-marco-MiniLM-L-6-v2`). | `sentence-transformers` |
| **GraphRAG** | Build entity graphs with `spaCy` + `networkx`; retrieve subgraphs. | entity co-occurrence edges |
| **Self-RAG** | Generate ‚Üí re-retrieve ‚Üí refine in a feedback loop. | two-stage generation |
|  **ColBERT / Late Interaction** | Fine-grained token-level matching for semantic precision. | `colbert-ai` |
| **Long-Context RAG** | Use long-context LLMs (e.g., Mistral 7B Instruct, LongT5). | full-context inference |
| **Multi-Retriever Ensemble** | Combine multiple retrievers with learned weights. | adaptive fusion |

#### Deliverables
| File | Description |
|------|--------------|
| `src/agents/retriever_experiment_agent.py` | your advanced retriever |
| `results/retrieval_comparison.json` | metrics vs baseline |
| `results/retrieval_plot.png` | visualization |

